extends: base

dataset: celebhq

model:
  name: vae
  params:
    z_channels: 4
    down_channels: [128, 256, 384]
    mid_channels: [384]
    down_sample: [true, true]
    attn_down: [false, false]
    norm_channels: 32
    num_heads: 4
    num_down_layers: 2
    num_mid_layers: 2
    num_up_layers: 2
  weights: null  # Path to pretrained weights (optional)

train:
  epochs: 3
  lr: 0.00001
  batch_size: 4
  disc_start: 7500
  disc_weight: 0.5
  perceptual_weight: 1.0
  kl_weight: 0.000005
  output_dir: 'outputs/celebhq_vae'
  autoencoder_acc_steps: 1
  autoencoder_img_save_steps: 64
  vae_autoencoder_ckpt_name: 'vae_autoencoder.pth'
  vae_discriminator_ckpt_name: 'vae_discriminator.pth'
